---
title: "AlphaLab Data Wrangling"
author: "Inigo Peng"
date: "2022-10-12"
runtime: shiny
output: html_document
---
# AlphaLab Data
## Description of Data

**Collection method:**

Sampling Bottles

**Raw File format:**

AlphaLab CSV lab report

**Monitoring (Project ID)**

Storm Water Sampling (SW), Tap Water Sampling (CalWATCH).

**WQX submittal required?**

Storm Water Sampling: YES. Tap Water Sampling: NO.

**Note:**

This script is a dynamic markdown where the user will be able to interact with the document. To run the document, click on "Run Document" to render it into an HTML format. 

Usually, to run a markdown script, the user needs to make sure the project is set to the appropriate working directory. However, since this is an interactive markdown, we do not have to worry about that. The files we need are the Alpha Lab excel files that needs to get updated, and the lookup_objects.rdata.

In these markdown documents, the shaded sections are the code that are used to process the data. If you have any question about any of the functions used, type in ? followed by the function (eg. ?mutate()) in the console,  or google search the function to see detailed documentation on the function.  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(readxl)
library(lubridate)
```

## Data transformations

First we need to load the lookup table named "lookup_object.rdata" that contains project ID lookup (eg.location FC1's corresponding project ID is CS), unit lookup (eg. Temperature, water - deg C), method lookup, method context lookup and project sites. Click Open. 

```{r}
fileInput("lookup_objects", "Load lookup_objects.rdata")

load_file <- reactive({
  req(input$lookup_objects)
  if (is.null(input$lookup_objects))
    return(NULL)
  inFile <- input$lookup_objects
  file <- inFile$datapath
  # load the file into session environment and get it from there
  sessionEnvir <- sys.frame()
  load(file, sessionEnvir)
})

```


After loading the lookup_objects.rdata, click on browse and find the appropriate Alpha Lab excel files on your computer. Select all of the files (could select multiple) that need to be transformed to wqx format.Since the original files are in xls format, we could read in the excel files using the function read_excel() from the readxl package. At the same time, this script will parse the SAMPLENAME column for the sample location in the column.

Once the parsing is finished, the header of the table will appear below this chunk.
```{r}
fileInput("alpha_files",
          "Choose AlphaLab Excel File",
          accept = ".xlsx",
          multiple = TRUE)

all_files <- reactive({
  req(input$alpha_files)
  raw_alpha_lab <-
    map_df(purrr::map(input$alpha_files$datapath, read_excel), rbind)
  for (row in 1:nrow(raw_alpha_lab)) {
    for (n in 1:length(strsplit(raw_alpha_lab$SAMPLENAME, " ")[[row]])) {
      if (strsplit(raw_alpha_lab$SAMPLENAME, " ")[[row]][n] %in% project_sites) {
        raw_alpha_lab$SAMPLENAME[row] = strsplit(raw_alpha_lab$SAMPLENAME, " ")[[row]][n]
      }
    }
  }
  return (raw_alpha_lab)
})

renderTable({
  head(all_files())
})

```


Alternatively, we could read in all of the files in the folder at once and bind them by row into one data frame. We do this by listing out all of the files in the folder using the function list.files(). 

We then create an empty data frame called raw_alpha_lab. We loop through the files in the folder, for each file, we use the above function read_excel() to read in the file. We then use the function rbind() to join each the data from each file to the empty data frame.

The end result is one data frame with all of the data from the folder.

Before transforming the results data into WQX format, we will create a function that will help to make the `Activity ID` column of WQX file. To make the Activity ID, it needs location ID, date, activity type, equipment name, depth, time and equipment comment. Simply run this function (line 142) with a mutate() statement to create the `Activity ID`.


To transform the data into WQX format, we will create columns based on WQX schema using the mutate() function from the tidyverse package. We will then drop the columns we do not need and reorder the data.

One function that is used a numerous time is the ifelse() function. This function lets the user create a condition, and if this condition is met, the column will be a specified value. If it is not met, it is a different value.

For example, in the code 

raw_alpha_lab |> 
mutate(Characteristic Name" = ifelse(ANALYTE == "E. Coli", "Escherichia coli", ANALYTE))

It could be read as: using the dataset raw_alpha_lab, we create a new column named `Characteristic Name`. If the cell value from the `ANALYTE` column from raw_alpha_lab is E. Coli (this is the condition), the corresponding cell value in the `Characteristic Name` column will be Eschericia coli. If the condition is not met, fill the rest of the `Characteristic Name` column with values from the `ANALYTE` column.

```{r}
make_activity_id <- function(location_id, date, activity_type, equipment_name, depth = NULL, time = NULL, equipment_comment = NULL) {
  YYYYMMDD <- gsub('/', '', date)
  activity <- ifelse(activity_type == "Sample-Routine", "SR", "FM")
  equipment <- case_when(
      equipment_name == "Probe/Sensor" ~ "PS",
      equipment_name == "Water Bottle" ~ "WB",
      TRUE ~ NA_character_
    )
  hhmm <- gsub(':', '', time)
  equipment_comment <- case_when(
    equipment_comment == "Hydrolab Surveyor DS5 Multiprobe" ~ "Hydro",
    equipment_comment == "AlgaeChek Ultra Fluorometer" ~ "Algae", 
    TRUE ~ NA_character_)
  depth <- ifelse(is.na(depth), "", depth)
  paste(location_id, YYYYMMDD, hhmm,activity, equipment, depth, equipment_comment, sep = ":")
}
```

```{r}
partial_clean_alpha_lab <- reactive({
  
  req(input$alpha_files)
  
  all_files <- all_files() |>
    mutate(
      "Project ID" = "SW",
    "Monitoring Location ID" = SAMPLENAME,
    "Activity ID User Supplied (PARENTs)" = NA,
    "Activity Type" = "Sample-Routine",
    "Activity Media Name" = MATRIX,
    "Activity Start Date" = format(mdy_hms(SAMPDATE), "%m/%d/%Y"),
    "Activity Start Time" = format(mdy_hms(SAMPDATE), "%H:%M"),
    "Activity Start Time Zone" = "PST",
    "Activity Depth/Height Measure" = "0.152",
    "Activity Depth/Height Unit" = "m",
    "Sample Collection Method ID" = "BVR SWQAPP",
    "Sample Collection Method Context" = "CA_BVR",
    "Sample Collection Equipment Name" = "Water Bottle",
    "Sample Collection Equipment Comment" = NA,
    "Characteristic Name" = case_when(
      ANALYTE == "E. Coli" ~ "Escherichia coli",
      ANALYTE == "Oil & Grease (HEM)" ~ "Oil and Grease",
      ANALYTE == "Phosphorus, total" ~ "Phosphorus",
      ANALYTE == "Total Organic Carbon" ~ "Organic carbon",
      TRUE ~ ANALYTE),
    "Characteristic Name User Supplied" = NA,
    "Method Speciation" = case_when(
      ANALYTE == "Nitrate as N" ~ "as N",
      ANALYTE == "Phosphorus, total" ~ "as P",
      ANALYTE == "Nitrate + Nitrite as N" ~ "as N",
      TRUE ~ NA_character_),
    "Result Detection Condition" = case_when(
      Result == "ND" ~ "Not Reported",
      Result == "Absent" ~ "Not Present",
      Result == "Present" ~ "Detected Not Quantified",
      TRUE ~ NA_character_),
    "Result Value" = ifelse(Result == "Absent" | Result == "ND" | Result == "Present", NA_character_, Result),
    "Result Unit" = ifelse(UNITS == ".", NA_character_, UNITS),
    "Result Measure Qualifier" = NA,
    "Result Sample Fraction" = "Total",
    "Result Status ID" = "Final",
    "ResultTemperatureBasis" = NA,
    "Statistical Base Code" = NA,
    "ResultTimeBasis" = NA,
    "Result Value Type" = ifelse(is.na(Result), NA_character_, "Actual"),
    "Result Analytical Method ID" = ifelse(is.na(METHODNAME), NA_character_, method_id_lookup[METHODNAME]),
    "Activity ID (CHILD-subset)" = make_activity_id(
      location_id = `Monitoring Location ID`,
      date = `Activity Start Date`,
      time = `Activity Start Time`,
      activity_type = `Activity Type`,
      equipment_name = `Sample Collection Equipment Name`,
      depth = `Activity Depth/Height Measure`
    ),
    "Result Analytical Method Context" = method_context_lookup[METHODNAME],
    "Analysis Start Date" = format(mdy_hms(ANADATE), "%m/%d/%Y"),
    "Result Detection/Quantitation Limit Type" = ifelse(DL == "NA", NA_character_, "Method Detection Level"),
    "Result Detection/Quantitation Limit Measure" = ifelse(DL == "NA", NA_character_, DL),
    "Result Detection/Quantitation Limit Unit" = ifelse(UNITS == ".", NA_character_, UNITS),
    "Result Comment" = NA
    
  ) %>%
  select(-c(0:48)) %>% 
  relocate("Activity ID (CHILD-subset)", .before = "Activity ID User Supplied (PARENTs)")
})

renderTable({
  head(partial_clean_alpha_lab())
})
```

One last step that we need to do before getting a WQX ready dataset is to make sure that both `Result Unit` and `Result Analytical Method Context` column is empty if the `Result Analytical Method ID` and `Result Unit` columns are respectively empty.

```{r}
clean_alpha_lab <- reactive({
  req(input$alpha_files)

  partial_clean_alpha_lab <-  partial_clean_alpha_lab() |>
    mutate(
      "Result Analytical Method Context" = ifelse(
        is.na(partial_clean_alpha_lab()$`Result Analytical Method ID`),
        NA_character_,
        partial_clean_alpha_lab()$`Result Analytical Method Context`
      ),
      "Result Unit" = ifelse(
        is.na(partial_clean_alpha_lab()$`Result Value`),
        NA_character_,
        partial_clean_alpha_lab()$`Result Unit`
      )
    ) |>
    relocate("Result Analytical Method Context", .before = "Analysis Start Date")
})


renderTable({
  head(clean_alpha_lab())
})

```

Lastly we export the data to a CSV file in the data folder. Cells with NAs are saved as blank cells.

```{r}
downloadHandler(
  filename = function() {
    paste("alpha-lab-data-", Sys.Date(), ".csv", sep = "")
  },
  content = function(file) {
    write.csv(
      clean_alpha_lab(), 
      file,
      na = '',
      row.names = FALSE)
  }
)
```




